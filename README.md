# ðŸŽ¨ PRODiGY_GENAI_02 â€“ Image Generation with Pre-trained Diffusion Models

This project showcases the use of **pre-trained diffusion models** like **Stable Diffusion** and **DALLÂ·E Mini** to generate AI images from text prompts. It was built as part of the **Generative AI Internship** at Prodigy InfoTech.

---

## ðŸŽ¯ Project Objectives

- Generate stunning, AI-generated visuals from textual prompts.
- Use and experiment with diffusion-based generative models.
- Explore and apply prompt engineering techniques.
- Demonstrate real-world use of Hugging Face tools.

---

##  How it Works Highlights

- âœ… Integrated Hugging Face's `diffusers` to load **Stable Diffusion** models
- âœ… Developed a prompt-based image generation pipeline using `torch`, `transformers`, and `PIL`
- âœ… Customized inference parameters like:
  - `num_inference_steps`
  - `guidance_scale`
- âœ… Saved and visualized generated images directly in Google Colab
- âœ… Used prompt engineering tricks (adjectives, styles) for creative control
- âœ… Compared results between different prompts and model settings

---

## ðŸ§° Tech Stack & Tools

- **Model:** Stable Diffusion / DALLÂ·E Mini
- **Libraries:**
  - `diffusers`
  - `transformers`
  - `torch`
  - `accelerate`
  - `PIL`
- **Platform:** Google Colab / Jupyter Notebook

---

## ðŸ“¥ Setup Instructions

1. Clone the repository:
   ```bash
   git clone https://github.com/diljithmon170/PRODIGY_GENAI_02.git
   cd PRODIGY_GENAI_02
